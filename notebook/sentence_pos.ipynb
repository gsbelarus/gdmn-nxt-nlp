{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "676ec0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import benepar\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7bac732",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "789491d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add LanguageDetector and assign it a string name\n",
    "@Language.factory(\"language_detector\")\n",
    "def create_language_detector(nlp, name):\n",
    "    return LanguageDetector(language_detection_function=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "353fc98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x264ce5613c0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"language_detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3af25f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package benepar_en3_large to\n",
      "[nltk_data]     C:\\Users\\gs199\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package benepar_en3_large is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benepar.download('benepar_en3_large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8c346d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<benepar.integrations.spacy_plugin.BeneparComponent at 0x264ce560bb0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea44bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\torch\\distributions\\distribution.py:44: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1db3d242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Apple', 'PROPN'), ('is', 'AUX'), ('looking', 'VERB'), ('at', 'ADP'), ('buying', 'VERB'), ('U.K.', 'PROPN'), ('startup', 'NOUN'), ('for', 'ADP'), ('$', 'SYM'), ('1', 'NUM'), ('billion', 'NUM')]\n"
     ]
    }
   ],
   "source": [
    "print([(w.text, w.pos_) for w in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef2d9508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False 383\n",
      "is be AUX VBZ aux xx True True 0\n",
      "looking look VERB VBG ROOT xxxx True False 0\n",
      "at at ADP IN prep xx True True 0\n",
      "buying buy VERB VBG pcomp xxxx True False 0\n",
      "U.K. U.K. PROPN NNP compound X.X. False False 384\n",
      "startup startup NOUN NN dobj xxxx True False 0\n",
      "for for ADP IN prep xxx True True 0\n",
      "$ $ SYM $ quantmod $ False False 394\n",
      "1 1 NUM CD compound d False False 394\n",
      "billion billion NUM CD pobj xxxx True False 394\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop, token.ent_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10c55e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple ORG\n",
      "U.K. U.K. GPE\n",
      "$1 billion $1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent, ent.lemma_, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b69438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple {'Number': 'Sing'}\n",
      "is {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "looking {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "at {}\n",
      "buying {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "U.K. {'Number': 'Sing'}\n",
      "startup {'Number': 'Sing'}\n",
      "for {}\n",
      "$ {}\n",
      "1 {'NumType': 'Card'}\n",
      "billion {'NumType': 'Card'}\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.morph.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "048603f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'en', 'score': 0.9999969772583737}\n",
      "Apple is looking at buying U.K. startup for $1 billion\n",
      "{'language': 'en', 'score': 0.9999949386792386}\n",
      "(S (NP (NNP Apple)) (VP (VBZ is) (VP (VBG looking) (PP (IN at) (S (VP (VBG buying) (NP (NNP U.K.) (NN startup)) (PP (IN for) (NP (QP ($ $) (CD 1) (CD billion))))))))))\n"
     ]
    }
   ],
   "source": [
    "# document level language detection. Think of it like average language of the document!\n",
    "print(doc._.language)\n",
    "# sentence level language detection\n",
    "for sent in doc.sents:\n",
    "   print(sent)\n",
    "   print(sent._.language)\n",
    "   print(sent._.parse_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66a20fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple nsubj looking {'Number': 'Sing'}\n",
      "is aux looking {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "looking ROOT looking {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "at prep looking {}\n",
      "buying pcomp at {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "U.K. compound startup {'Number': 'Sing'}\n",
      "startup dobj buying {'Number': 'Sing'}\n",
      "for prep buying {}\n",
      "$ quantmod billion {}\n",
      "1 compound billion {'NumType': 'Card'}\n",
      "billion pobj for {'NumType': 'Card'}\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.morph.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb6a9f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (NNP Apple)) (VP (VBZ is) (VP (VBG looking) (PP (IN at) (S (VP (VBG buying) (NP (NNP U.K.) (NN startup)) (PP (IN for) (NP (QP ($ $) (CD 1) (CD billion))))))))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Apple"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = list(doc.sents)[0]\n",
    "print(sent._.parse_string)\n",
    "sent._.labels\n",
    "list(sent._.children)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5e81967",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ru = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5854845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x2657d806bf0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_ru.add_pipe(\"language_detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc4d8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ru = nlp_ru(\"Покажи все организации из города Минска и Пинска.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "daf157b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Покажи', 'VERB'), ('все', 'DET'), ('организации', 'NOUN'), ('из', 'ADP'), ('города', 'NOUN'), ('Минска', 'PROPN'), ('и', 'CCONJ'), ('Пинска', 'PROPN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "print([(w.text, w.pos_) for w in doc_ru])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10cb96ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "[E894] The 'noun_chunks' syntax iterator is not implemented for language 'ru'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Golden\\nx\\gdmn-nxt-nlp\\notebook\\sentence_pos.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Golden/nx/gdmn-nxt-nlp/notebook/sentence_pos.ipynb#ch0000029?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m noun \u001b[39min\u001b[39;00m doc_ru\u001b[39m.\u001b[39mnoun_chunks:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Golden/nx/gdmn-nxt-nlp/notebook/sentence_pos.ipynb#ch0000029?line=1'>2</a>\u001b[0m   \u001b[39mprint\u001b[39m(noun\u001b[39m.\u001b[39mtext, noun\u001b[39m.\u001b[39mroot\u001b[39m.\u001b[39mtext, noun\u001b[39m.\u001b[39mroot\u001b[39m.\u001b[39mdep_)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\spacy\\tokens\\doc.pyx:852\u001b[0m, in \u001b[0;36mnoun_chunks\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: [E894] The 'noun_chunks' syntax iterator is not implemented for language 'ru'."
     ]
    }
   ],
   "source": [
    "for noun in doc_ru.noun_chunks:\n",
    "  print(noun.text, noun.root.text, noun.root.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7643e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent #1\n",
      "############################################################\n",
      "Покажи 0\n",
      "показать VERB VERB Xxxxx True False\n",
      "ROOT 0 Покажи 0\n",
      "[] [организации, .] []\n",
      "{'Aspect': 'Perf', 'Mood': 'Imp', 'Number': 'Sing', 'Person': 'Second', 'VerbForm': 'Fin', 'Voice': 'Act'}\n",
      "############################################################\n",
      "все 1\n",
      "весь DET DET xxx True True\n",
      "det 2 организации 0\n",
      "[0] [все, города] []\n",
      "{'Animacy': 'Inan', 'Case': 'Acc', 'Number': 'Plur'}\n",
      "############################################################\n",
      "организации 2\n",
      "организация NOUN NOUN xxxx True False\n",
      "obj 0 Покажи 0\n",
      "[] [организации, .] []\n",
      "{'Animacy': 'Inan', 'Case': 'Acc', 'Gender': 'Fem', 'Number': 'Plur'}\n",
      "############################################################\n",
      "из 3\n",
      "из ADP ADP xx True True\n",
      "case 4 города 0\n",
      "[2, 0] [из, Минска] []\n",
      "{}\n",
      "############################################################\n",
      "города 4\n",
      "город NOUN NOUN xxxx True False\n",
      "nmod 2 организации 0\n",
      "[0] [все, города] []\n",
      "{'Animacy': 'Inan', 'Case': 'Gen', 'Gender': 'Masc', 'Number': 'Sing'}\n",
      "############################################################\n",
      "Минска 5\n",
      "минск PROPN PROPN Xxxxx True False\n",
      "appos 4 города 0\n",
      "[2, 0] [из, Минска] []\n",
      "{'Animacy': 'Inan', 'Case': 'Gen', 'Gender': 'Masc', 'Number': 'Sing'}\n",
      "############################################################\n",
      "и 6\n",
      "и CCONJ CCONJ x True True\n",
      "cc 7 Пинска 0\n",
      "[5, 4, 2, 0] [и] [Минска]\n",
      "{}\n",
      "############################################################\n",
      "Пинска 7\n",
      "пинск PROPN PROPN Xxxxx True False\n",
      "conj 5 Минска 0\n",
      "[4, 2, 0] [Пинска] [Пинска]\n",
      "{'Animacy': 'Inan', 'Case': 'Gen', 'Gender': 'Masc', 'Number': 'Sing'}\n",
      "############################################################\n",
      ". 8\n",
      ". PUNCT PUNCT . False False\n",
      "punct 0 Покажи 0\n",
      "[] [организации, .] []\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "sent_n = 1\n",
    "for sent in doc_ru.sents:\n",
    "  print('sent #{}'.format(sent_n))\n",
    "  sent_n += 1        \n",
    "  for token in sent:\n",
    "      print('############################################################')\n",
    "      print(token.text, token.i)\n",
    "      print(token.lemma_, token.pos_, token.tag_, token.shape_, token.is_alpha, token.is_stop)\n",
    "      print(token.dep_, token.head.i, token.head.text, token.head.cluster)\n",
    "      print([an.i for an in token.head.ancestors], [child for child in list(token.head.children)], list(token.head.conjuncts))\n",
    "      print(token.morph.to_dict())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96087908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Покажи ROOT Покажи {'Aspect': 'Perf', 'Mood': 'Imp', 'Number': 'Sing', 'Person': 'Second', 'VerbForm': 'Fin', 'Voice': 'Act'}\n",
      "все det организации {'Animacy': 'Inan', 'Case': 'Acc', 'Number': 'Plur'}\n",
      "организации obj Покажи {'Animacy': 'Inan', 'Case': 'Acc', 'Gender': 'Fem', 'Number': 'Plur'}\n",
      "из case города {}\n",
      "города nmod организации {'Animacy': 'Inan', 'Case': 'Gen', 'Gender': 'Masc', 'Number': 'Sing'}\n",
      "Минска appos города {'Animacy': 'Inan', 'Case': 'Gen', 'Gender': 'Masc', 'Number': 'Sing'}\n",
      "и cc Пинска {}\n",
      "Пинска conj Минска {'Animacy': 'Inan', 'Case': 'Gen', 'Gender': 'Masc', 'Number': 'Sing'}\n",
      ". punct Покажи {}\n"
     ]
    }
   ],
   "source": [
    "for token in doc_ru:\n",
    "    print(token.text, token.dep_, token.head.text, token.morph.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9765fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'mk', 'score': 0.7142164920414136}\n",
      "Покажи все организации из города Минска и Пинска. {'language': 'ru', 'score': 0.8571386539265075}\n"
     ]
    }
   ],
   "source": [
    "# document level language detection. Think of it like average language of the document!\n",
    "print(doc_ru._.language)\n",
    "# sentence level language detection\n",
    "for sent in doc_ru.sents:\n",
    "   print(sent, sent._.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e6455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минска минск LOC\n",
      "Пинска пинск LOC\n"
     ]
    }
   ],
   "source": [
    "for sent in doc_ru.sents:\n",
    "  for ent in sent.ents:\n",
    "      print(ent, ent.lemma_, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe5e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ru = nlp_ru(\"Василий Петрович Кукушкин купил машину жигули в городе Минске\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a84b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Василий Петрович Кукушкин 0 василий петрович кукушкин PER 0 25\n",
      "Минске 0 минск LOC 55 61\n"
     ]
    }
   ],
   "source": [
    "for ent in doc_ru.ents:\n",
    "    print(ent, ent.ent_id, ent.lemma_, ent.label_, ent.start_char, ent.end_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607e9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b7a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Василий nsubj купил {'Animacy': 'Anim', 'Case': 'Nom', 'Gender': 'Masc', 'Number': 'Sing'} 0 PER\n",
      "Петрович appos Василий {'Animacy': 'Anim', 'Case': 'Nom', 'Gender': 'Masc', 'Number': 'Sing'} 8 PER\n",
      "Кукушкин appos Василий {'Animacy': 'Anim', 'Case': 'Nom', 'Gender': 'Masc', 'Number': 'Sing'} 17 PER\n",
      "купил ROOT купил {'Aspect': 'Perf', 'Gender': 'Masc', 'Mood': 'Ind', 'Number': 'Sing', 'Tense': 'Past', 'VerbForm': 'Fin', 'Voice': 'Act'} 26 \n",
      "машину obj купил {'Animacy': 'Inan', 'Case': 'Acc', 'Gender': 'Fem', 'Number': 'Sing'} 32 \n",
      "жигули obj купил {'Aspect': 'Perf', 'Mood': 'Ind', 'Number': 'Plur', 'Tense': 'Past', 'VerbForm': 'Fin', 'Voice': 'Act'} 39 \n",
      "в case городе {} 46 \n",
      "городе nmod жигули {'Animacy': 'Inan', 'Case': 'Loc', 'Gender': 'Masc', 'Number': 'Sing'} 48 \n",
      "Минске appos городе {'Animacy': 'Inan', 'Case': 'Loc', 'Gender': 'Masc', 'Number': 'Sing'} 55 LOC\n"
     ]
    }
   ],
   "source": [
    "for token in doc_ru:\n",
    "    print(token.text, token.dep_, token.head.text, token.morph.to_dict(), token._._start, token.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b7e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(\"Apple is looking at buying U.K. startup for $1 billion. Это предложение не на английском. Третье предложение.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed37ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'bg', 'score': 0.9999947070009931}\n",
      "Apple is looking at buying U.K. startup for $1 billion. {'language': 'en', 'score': 0.9999951062958017}\n",
      "Это предложение не на английском. {'language': 'ru', 'score': 0.8571400083231521}\n",
      "Третье предложение. {'language': 'ru', 'score': 0.9999955231308968}\n"
     ]
    }
   ],
   "source": [
    "# document level language detection. Think of it like average language of the document!\n",
    "print(doc2._.language)\n",
    "# sentence level language detection\n",
    "for sent in doc2.sents:\n",
    "   print(sent, sent._.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a1f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"show me all companies from minsk and pinsk\")\n",
    "#displacy.serve(doc, style=\"dep\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
